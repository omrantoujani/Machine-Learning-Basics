{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n",
    "Gradient descent approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [4 5]\n",
      " [2 5]] [1 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [4, 5], [2, 5]])\n",
    "y = np.array([1, 0, 0])\n",
    "\n",
    "print X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1]\n",
      " [3 5]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[3, 1], [3, 5]])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Logistic Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        '''\n",
    "        Computes the sigmoid\n",
    "        '''\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def loss_function(self):\n",
    "        '''\n",
    "        Computes log loss for binary classification. \n",
    "        In case ofmulti class classigication, we need to compute cross entropy\n",
    "        '''\n",
    "        loss = (-self.y * np.log(self.train_pred + 0.0001) - (1-self.y)*np.log(1-self.train_pred + 0.0001)).mean()\n",
    "        return loss\n",
    "    \n",
    "    def gradient_descent(self):\n",
    "        '''\n",
    "        Updates the weights by computing: W - learning rate * gradient.\n",
    "        gradient = x * (sigmoid(z) - y)\n",
    "        \n",
    "        Returns:\n",
    "        W - Updates weights\n",
    "        '''\n",
    "        grad = np.dot(self.X.T, (self.train_pred - self.y)) * self.learning_rate\n",
    "        self.W = self.W - grad\n",
    "        return self.W\n",
    "    \n",
    "    def log_reg(self, learning_rate, iterations):\n",
    "        '''\n",
    "        Function that iterates over \"iterations\" to compute loss and then \n",
    "        performs gradient descent to update the weights\n",
    "        \n",
    "        Inputs:\n",
    "        learning_rate - learning rate\n",
    "        iterations - Number of iteations\n",
    "        \n",
    "        ''' \n",
    "        self.learning_rate = learning_rate\n",
    "        self.W = np.random.randn(len(self.X[0])) # weights are randomly initialised at first\n",
    "        for it in range(iterations):\n",
    "            self.train_pred = []\n",
    "            for row in self.X:\n",
    "                z = np.sum([row[i] * self.W[i] for i in range(len(row))])\n",
    "                self.train_pred.append(self.sigmoid(z))\n",
    "            self.train_pred = np.array(self.train_pred)\n",
    "            loss = self.loss_function()\n",
    "            \"\"\"print(Epoch {it}, loss {loss})\"\"\"\n",
    "            print('Epoch: '+  str(it))\n",
    "            print('loss: '+ str(loss))\n",
    "            self.W = self.gradient_descent()\n",
    "        print('Coefficients: '+ str(self.W))\n",
    "        \n",
    "    def predict(self, test):\n",
    "        '''\n",
    "        Multiply the features of every row with the corresponding coefficients\n",
    "        '''\n",
    "        self.test_pred = []\n",
    "        for row in test:\n",
    "            z = np.sum([row[i] * self.W[i] for i in range(len(row))])\n",
    "            self.test_pred.append(self.sigmoid(z))\n",
    "        print('Predictions: '+ str(self.test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit logistic regression to get the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "loss: 1.7676618303055556\n",
      "Epoch: 1\n",
      "loss: 0.544093871752797\n",
      "Epoch: 2\n",
      "loss: 0.4891392219221098\n",
      "Epoch: 3\n",
      "loss: 0.4713190775481871\n",
      "Epoch: 4\n",
      "loss: 0.468902988672947\n",
      "Epoch: 5\n",
      "loss: 0.468544680916872\n",
      "Epoch: 6\n",
      "loss: 0.4682778105295354\n",
      "Epoch: 7\n",
      "loss: 0.46802156412413054\n",
      "Epoch: 8\n",
      "loss: 0.4677740603034704\n",
      "Epoch: 9\n",
      "loss: 0.4675349734463429\n",
      "Coefficients: [-0.17284567 -0.27739538]\n"
     ]
    }
   ],
   "source": [
    "model.log_reg(learning_rate=0.1, iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the log loss decreases with every iteration\n",
    "\n",
    "### Predict target values for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0.310896293236343, 0.12948568309901753]\n"
     ]
    }
   ],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
